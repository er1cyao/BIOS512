{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d684172-4b94-42cf-bda2-e11952420d86",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "#### Course Notes\n",
    "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
    "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
    "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839a5ba-62f4-4699-baea-018afda70786",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
   "metadata": {},
   "source": [
    "#### a) Make a function to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d835a571",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(httr)\n",
    "library(tokenizers)\n",
    "\n",
    "tokenize_text <- function(text) {\n",
    "    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86145513-294b-4894-a02c-8ae60e2c616e",
   "metadata": {},
   "source": [
    "#### b) Make a function generate keys for ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60eba599",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "key_from <- function(ngram, sep = \"\\x1f\") {\n",
    "    paste(ngram, collapse=sep)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988c2c-b230-467f-b519-72bc85b93b43",
   "metadata": {},
   "source": [
    "#### c) Make a function to build an ngram table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f82c14",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
    "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
    "    tbl <- new.env(parent = emptyenv())\n",
    "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
    "        ngram <- tokens[i:(i + n - 2L)]\n",
    "        next_word <- tokens[i + n - 1L]\n",
    "        key <- paste(ngram, collapse = sep)\n",
    "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "        if (next_word %in% names(counts)) {\n",
    "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
    "        } else {\n",
    "            counts[[next_word]] <- 1L\n",
    "        }\n",
    "        tbl[[key]] <- counts\n",
    "    }\n",
    "    tbl\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6db37-abce-4705-9784-e1b898174f00",
   "metadata": {},
   "source": [
    "#### d) Function to digest the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f68ceb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "digest_text <- function(text, n) {\n",
    "    tokens <- tokenize_text(text)\n",
    "    build_ngram_table(tokens, n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
   "metadata": {},
   "source": [
    "#### e) Function to digest the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "432dc151",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "digest_url <- function(url, n) {\n",
    "    res <- httr::GET(url)\n",
    "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
    "    digest_text(txt,n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
   "metadata": {},
   "source": [
    "#### f) Function that gives random start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7162e941",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "random_start <- function(tbl, sep = \"\\x1f\") {\n",
    "    keys <- ls(envir = tbl, all.names=TRUE)\n",
    "    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n",
    "    picked <- sample(keys, 1)\n",
    "    strsplit(picked, sep, fixed=TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
   "metadata": {},
   "source": [
    "#### g) Function to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23c62316",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
    "    key <- paste(ngram, collapse = sep)\n",
    "    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "    if (length(counts) == 0) return(NA_character_)\n",
    "    sample(names(counts), size=1, prob=as.numeric(counts))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f4002-4932-42c4-a4af-8689293a5857",
   "metadata": {},
   "source": [
    "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e69c31e6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
    "    force(tbl); n <- as.integer(n); force(sep)\n",
    "    function(start_words = NULL, length = 10L) {\n",
    "        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n",
    "            start_words <- random_start(tbl, sep=sep)\n",
    "        }\n",
    "        word_sequence <- start_words\n",
    "        for (i in seq_len(max(0L, length - length(start_words)))) {\n",
    "            ngram <- tail(word_sequence, n - 1L)\n",
    "            next_word <- predict_next_word(tbl, ngram, sep=sep)\n",
    "            if (is.na(next_word)) break\n",
    "            word_sequence <- c(word_sequence, next_word)\n",
    "        }\n",
    "        paste(word_sequence, collapse= \" \")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8a6b24a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gen_txt <- function(source, n = 2, length = 20L, start_words = NULL, from_url = FALSE){\n",
    "    tbl <- if (from_url) {\n",
    "    digest_url(source, n)\n",
    "  } else {\n",
    "    digest_text(source, n)\n",
    "  }\n",
    "  generator <- make_ngram_generator(tbl, n)\n",
    "  generator(start_words = start_words, length = length)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### For this question, set `seed=2025`.\n",
    "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358bf4d6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"the king\"\n",
      "[1] \"now to think it but did lie in my dreams and now truly i had\"\n"
     ]
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "url <- \"https://www.gutenberg.org/cache/epub/10662/pg10662.txt\"\n",
    "\n",
    "txtai <- gen_txt(\n",
    "    source = url,\n",
    "    n = 3,\n",
    "    length = 15,\n",
    "    start_words = c(\"the\",\"king\"),\n",
    "    from_url = TRUE)\n",
    "\n",
    "txtaii <-  gen_txt(\n",
    "    source = url,\n",
    "    n = 3,\n",
    "    length = 15,\n",
    "    start_words = NULL,\n",
    "    from_url = TRUE)\n",
    "\n",
    "print(txtai)\n",
    "print(txtaii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
   "metadata": {},
   "source": [
    "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
   "metadata": {},
   "source": [
    "#### c) Explain in 1-2 sentences the difference in content generated from each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ee251e6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"the king he added to the entire exclusion of the swords were made prisoners the\"\n",
      "[1] \"king was campaigning in france denmark germany switzerland and livonia figures 5 and the sword\"\n"
     ]
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "urlb <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
    "\n",
    "txtbi <- gen_txt(\n",
    "    source = urlb,\n",
    "    n = 3,\n",
    "    length = 15,\n",
    "    start_words = c(\"the\",\"king\"),\n",
    "    from_url = TRUE)\n",
    "\n",
    "txtbii <-  gen_txt(\n",
    "    source = urlb,\n",
    "    n = 3,\n",
    "    length = 15,\n",
    "    start_words = NULL,\n",
    "    from_url = TRUE)\n",
    "\n",
    "print(txtbi)\n",
    "print(txtbii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e19808",
   "metadata": {},
   "source": [
    "The difference in content generated from the first is that the grimms fairy tales is a narrative based text therefore it could be shorter when generating things related to \"the king.\" For the ancient armour one it could have multiple areas and it could pick a longer one compared to in a narrative type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### a) What is a language learning model? \n",
    "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d999cf",
   "metadata": {},
   "source": [
    "a) A language learning model is one that is trained to understand or generate human language through the process of learning pattern in text. It can be used to predict the next word or write longer bits of text based on use case.\n",
    "\n",
    "b) If the internet goes down, you can use an already trained model or also have existing frameworks that can load and run models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** |  |\n",
    "| **Terminal emulator** |  |\n",
    "| **Process** |  |\n",
    "| **Signal** |  |\n",
    "| **Standard input** |  |\n",
    "| **Standard output** |  |\n",
    "| **Command line argument** |  |\n",
    "| **The environment** |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fabbcab",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "shell is the program that interprets commands and in this case the shell reads the command and runs the mkdir program\n",
    "The teminal emulator is the app that is the window for writing commands. That is the location of typing the mkdir projact\n",
    "Process is an instance of the program you run. It creates a process mkdir that runs and then quits\n",
    "Signal is the message that is sent to a process. You can stop a process such as mkdir for example\n",
    "Standardinput is the default input.mkdir does not need input but other commands use it \n",
    "Standard output is the default location a program writes the output. mkdir project does not have this but you would see an error message in this area\n",
    "command line arument is the added information such as project in this case, the extra argument\n",
    "the environment is the variables and settings availible for different programs. other variables in the environment like PATH can help with this process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
    "#### a) What are the programs?\n",
    "#### b) Explain what this command is doing, part by part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb80b04",
   "metadata": {},
   "source": [
    "a) the command has the programs find that looks in the directory for files, xargs, that passes inputs to another command and grap, looking for text in files\n",
    "b)The find. -iname \"*.R\" looks for the files ending in .R in the cur directory\n",
    "-iname makes it case sensitive\n",
    "xargs grep read_csv takes file name and passes it into grap and then it searches through .R files for the string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n",
    "#### a) Show the response when you run `docker run hello-world`.\n",
    "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
    "#### c) How do you log in to the RStudio server?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08fe00",
   "metadata": {},
   "source": [
    "(base) MacBook-Pro-225:~ ericyao$ docker run hello-world\n",
    "Unable to find image 'hello-world:latest' locally\n",
    "latest: Pulling from library/hello-world\n",
    "198f93fd5094: Pull complete \n",
    "Digest: sha256:f7931603f70e13dbd844253370742c4fc4202d290c80442b2e68706d8f33ce26\n",
    "Status: Downloaded newer image for hello-world:latest\n",
    "\n",
    "Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly.\n",
    "\n",
    "To generate this message, Docker took the following steps:\n",
    " 1. The Docker client contacted the Docker daemon.\n",
    " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
    "    (arm64v8)\n",
    " 3. The Docker daemon created a new container from that image which runs the\n",
    "    executable that produces the output you are currently reading.\n",
    " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
    "    to your terminal.\n",
    "\n",
    "To try something more ambitious, you can run an Ubuntu container with:\n",
    " $ docker run -it ubuntu bash\n",
    "\n",
    "Share images, automate workflows, and more with a free Docker ID:\n",
    " https://hub.docker.com/\n",
    "\n",
    "For more examples and ideas, visit:\n",
    " https://docs.docker.com/get-started/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cf03f",
   "metadata": {},
   "source": [
    "run --platform linux/amd64 -it rocker/verse /bin/bash\n",
    "Unable to find image 'rocker/verse:latest' locally\n",
    "latest: Pulling from rocker/verse\n",
    "2c9ba66d5dbe: Pull complete \n",
    "bcdf914130e3: Pull complete \n",
    "983a57e0f10d: Pull complete \n",
    "04c61279cc76: Pull complete \n",
    "53593fccee71: Pull complete \n",
    "255aa55589e3: Pull complete \n",
    "7da3fea5923e: Pull complete \n",
    "7f54ce591537: Pull complete \n",
    "3c7cdccc4be7: Pull complete \n",
    "7acb5d2ece3f: Pull complete \n",
    "fc14ca29bd0e: Pull complete \n",
    "4b3ffd8ccb52: Pull complete \n",
    "b615453605c4: Pull complete \n",
    "7bca23a8b40d: Pull complete \n",
    "999e4b8f7ed8: Pull complete \n",
    "b71e78fefbbb: Pull complete \n",
    "33aa1b89cc9c: Pull complete \n",
    "e82dc96b20d6: Pull complete \n",
    "a7519eda3916: Pull complete \n",
    "339259f92146: Pull complete \n",
    "2a63ed8b2250: Pull complete \n",
    "3deebd4cc2ea: Pull complete \n",
    "12b920580d3a: Pull complete \n",
    "Digest: sha256:96e1068eed2400e24c337a7ab53c7aab136970d92c1612bb3a1bb0c8972c7bf4\n",
    "Status: Downloaded newer image for rocker/verse:latest\n",
    "root@3595e7f6f751:/# docker run -it -p 8787:8787 rocker/verse\n",
    "bash: docker: command not found\n",
    "root@3595e7f6f751:/# exit\n",
    "exit\n",
    "(base) MacBook-Pro-225:~ ericyao$ docker run --platform linux/amd64 -it -p 8787:8787 rocker/verse\n",
    "[s6-init] making user provided files available at /var/run/s6/etc...exited 0.\n",
    "[s6-init] ensuring user provided files have correct perms...exited 0.\n",
    "[fix-attrs.d] applying ownership & permissions fixes...\n",
    "[fix-attrs.d] done.\n",
    "[cont-init.d] executing container initialization scripts...\n",
    "[cont-init.d] 01_set_env: executing... \n",
    "skipping /var/run/s6/container_environment/HOME\n",
    "skipping /var/run/s6/container_environment/RSTUDIO_VERSION\n",
    "[cont-init.d] 01_set_env: exited 0.\n",
    "[cont-init.d] 02_userconf: executing... \n",
    "\n",
    "\n",
    "The password is set to Oungaewohngei9ei\n",
    "If you want to set your own password, set the PASSWORD environment variable. e.g. run with:\n",
    "docker run -e PASSWORD=<YOUR_PASS> -p 8787:8787 rocker/rstudio\n",
    "\n",
    "\n",
    "[cont-init.d] 02_userconf: exited 0.\n",
    "[cont-init.d] done.\n",
    "[services.d] starting services\n",
    "[services.d] done.\n",
    "TTY detected. Printing informational message about logging configuration. Logging configuration loaded from '/etc/rstudio/logging.conf'. Logging to 'syslog'.\n",
    "\n",
    "TTY detected. Printing informational message about logging configuration. Logging configuration loaded from '/etc/rstudio/logging.conf'. Logging to 'syslog'.\n",
    "TTY detected. Printing informational message about logging configuration. Logging configuration loaded from '/etc/rstudio/logging.conf'. Logging to 'syslog'.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0029ef5",
   "metadata": {},
   "source": [
    "you log into rstudio by using the username rstudio and password that is either automatically generated or you select it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
